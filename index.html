<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>index</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <link rel="stylesheet" href="style.css" />
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<h1 id="algorithmic-statistics-mit-fall-2025">Algorithmic Statistics, MIT, Fall 2025</h1>
<h3 id="basics">Basics</h3>
<ul>
<li>Instructor: <a href="https://www.samuelbhopkins.com">Sam Hopkins</a></li>
<li>TA: <a href="https://ittairubinstein.bitbucket.io/">Ittai Rubinstein</a></li>
<li>Lectures: Mondays and Wednesdays, 2:30-4:00</li>
<li>Location: 32-124</li>
<li>Office Hours: TBA</li>
<li><a href="syllabus.pdf">Syllabus</a></li>
</ul>
<h3 id="lectures">Lectures</h3>
<table>
<colgroup>
<col style="width: 11%" />
<col style="width: 6%" />
<col style="width: 74%" />
<col style="width: 4%" />
<col style="width: 4%" />
</colgroup>
<thead>
<tr class="header">
<th>Lecture number</th>
<th>Date</th>
<th>Lecture topic</th>
<th>Notes</th>
<th>Video</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>9/3/25</td>
<td>intro, le cam, uniformity testing lower bound</td>
<td><a href="lecture-1-introduction.pdf">draft</a></td>
<td></td>
</tr>
<tr class="even">
<td>2</td>
<td>9/8/25</td>
<td>overview, linear and logistic regression, start sparse regression</td>
<td><a href="lecture-2-overview-and-linear-predictors.pdf">draft</a></td>
<td></td>
</tr>
<tr class="odd">
<td>3</td>
<td>9/10/25</td>
<td>sparse regression, compressed sensing</td>
<td><a href="https://www.cambridge.org/core/books/algorithmic-aspects-of-machine-learning/165FD1899783C6D7162235AE405685DB">Moitra book</a>, Ch. 5</td>
<td></td>
</tr>
<tr class="even">
<td>4</td>
<td>9/15/25</td>
<td>learning a gaussian and a product distribution – tv versus parameter learning</td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>5</td>
<td>9/17/25</td>
<td>introduction to MRFs, ising uniformity testing</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>6</td>
<td>9/22/25</td>
<td>tree-structured graphical models I – belief propagation</td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>7</td>
<td>9/24/25</td>
<td>tree-structured graphical models II – chow-liu, fano</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>8</td>
<td>9/29/25</td>
<td>parameter learning MRFs</td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>9</td>
<td>10/1/25</td>
<td>tv learning MRFs, tournament</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>10</td>
<td>10/6/25</td>
<td>kesten-stigum bound, temperature</td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>11</td>
<td>10/8/25</td>
<td>log sobolev – sampling and concentration of measure</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>12</td>
<td>10/15/25</td>
<td>svd, pca, best rank-one approximation (steurer notes)</td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>13</td>
<td>10/20/25</td>
<td>spectral clustering I: gaussian mixtures</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>14</td>
<td>10/22/25</td>
<td>spectral clustering II: stochastic block model</td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>15</td>
<td>10/27/25</td>
<td>stochastic block model robustness and ultra-sparse regime – grothendieck inequality and sdp</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>16</td>
<td>10/29/25</td>
<td>matrix completion</td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>17</td>
<td>11/3/25</td>
<td>tensor decomposition I: Jenrich’s algorithm</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>18</td>
<td>11/5/25</td>
<td>tensor decomposition II: ICA, HMMs, and friends</td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>19</td>
<td>11/12/25</td>
<td>robust mean estimation via filter</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>20</td>
<td>11/17/25</td>
<td>robust learning ising models</td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>21</td>
<td>11/19/25</td>
<td>SQ I</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>22</td>
<td>11/24/25</td>
<td>SQ II – friends of SQ including low degree, overlap gap, SoS</td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>23</td>
<td>11/26/25</td>
<td>planted clique – robust sparse mean estimation</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>24</td>
<td>12/1/25</td>
<td>lwe reduction??</td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>25</td>
<td>12/3/25</td>
<td>(sam traveling – possibly cancel class or rehearse presentations)</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>26</td>
<td>12/8/25</td>
<td>project presentations</td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>27</td>
<td>12/10/25</td>
<td>project presentations</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<h3 id="assignments">Assignments</h3>
</body>
</html>
